from abc import ABC, abstractmethod
from pathlib import Path
from typing import TYPE_CHECKING, Literal

if TYPE_CHECKING:
    import torch

import numpy as np
from funlib.geometry import Coordinate

from .utils import PydanticCoordinate, StrictBaseModel


class Model(ABC, StrictBaseModel):
    """
    A base class for defining the common attributes and methods for all
    model types.
    """

    in_channels: int
    min_input_shape: PydanticCoordinate
    min_output_shape: PydanticCoordinate
    min_step_shape: PydanticCoordinate
    out_channels: list[int | None] | int | None
    out_range: tuple[float, float]

    @property
    def context(self) -> Coordinate:
        """
        The context required to make tile artifact free predictions
        with this model.
        """
        return (self.eval_input_shape - self.eval_output_shape) // 2

    @abstractmethod
    def model(self) -> "torch.nn.Module":
        """
        A getter for a plain `torch.nn.Module` that can be called to
        generate the desired predictions. This should load the appropriate
        model weights.
        """
        pass

    @property
    @abstractmethod
    def eval_input_shape(self) -> Coordinate:
        """
        The input shape to use during prediction.
        """
        pass

    @property
    @abstractmethod
    def eval_output_shape(self) -> Coordinate:
        """
        The output shape to expect after providing data with shape
        `self.eval_input_shape()`
        """
        pass

    @property
    @abstractmethod
    def num_out_channels(self) -> list[int | None]:
        """
        The number of channels in each output prediction generated by this
        model. This is expected in a list to account for models that
        generate multiple output arrays.
        """
        pass

    def to_uint8(self, out_data: np.ndarray) -> np.ndarray:
        """
        A function defining the conversion function to go from model
        outputs to `np.uint8` for writing to zarr.
        """
        return np.clip(out_data * 255, 0, 255).astype(np.uint8)

    def from_uint8(self, data: np.ndarray) -> np.ndarray:
        """
        A function defining the conversion function to go from `np.uint8`
        back to `np.float32`
        """
        return data.astype(np.float32) / 255


class TorchModel(Model):
    checkpoint_type: Literal["torch"] = "torch"
    model_path: Path
    checkpoint_file: Path | None = None
    pred_size_growth: PydanticCoordinate | None = None

    def model(self):
        import torch

        model = torch.load(self.model_path, map_location="cpu")

        if self.checkpoint_file is not None:
            model.load_state_dict(
                torch.load(self.checkpoint_file, map_location="cpu")["model_state_dict"]
            )

        return model

    @property
    def eval_input_shape(self) -> Coordinate:
        input_shape = Coordinate(self.min_input_shape)

        if self.pred_size_growth is not None:
            assert np.sum(self.pred_size_growth % Coordinate(self.min_step_shape)) == 0
        if self.pred_size_growth is not None:
            input_shape = input_shape + self.pred_size_growth
        return input_shape

    @property
    def eval_output_shape(self) -> Coordinate:
        output_shape = Coordinate(self.min_output_shape)
        if self.pred_size_growth is not None:
            output_shape = output_shape + self.pred_size_growth
        return output_shape

    @property
    def num_out_channels(self) -> list[int | None]:
        num_channels = self.out_channels

        if isinstance(num_channels, int) or num_channels is None:
            return [num_channels]
        elif isinstance(num_channels, list):
            return num_channels

    def to_uint8(self, out_data: np.ndarray) -> np.ndarray:
        out_min, out_max = self.out_range
        return np.clip((out_data + out_min) / (out_max - out_min) * 255, 0, 255).astype(
            np.uint8
        )
